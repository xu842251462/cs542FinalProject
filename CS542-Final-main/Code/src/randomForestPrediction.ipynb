{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 539,
   "id": "ideal-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make needed imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "naked-window",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and testing data\n",
    "training_data = pd.read_pickle(\"../data/train.pkl\")\n",
    "testing_data = pd.read_pickle(\"../data/test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "outputs": [
    {
     "data": {
      "text/plain": "            0         1         2         3         4         5         6   \\\n0     0.866667  0.353333  0.372905  0.041250  0.000000  0.003861  0.639175   \n1     0.533333  0.313333  0.399441  0.050000  0.001156  0.001365  0.639175   \n2     0.400000  0.295556  0.410615  0.052500  0.001156  0.000906  0.639175   \n3     0.466667  0.300000  0.410615  0.051250  0.000578  0.000575  0.628866   \n4     0.333333  0.295556  0.405028  0.053125  0.000578  0.000073  0.659794   \n...        ...       ...       ...       ...       ...       ...       ...   \n1281  0.666667  0.186667  0.734637  0.018125  0.300578  0.002811  0.072165   \n1282  0.866667  0.311111  0.555866  0.015625  0.368786  0.000563  0.958763   \n1283  0.200000  0.011111  0.997207  0.016250  0.234104  0.000000  0.051546   \n1284  0.000000  0.044444  0.927374  0.015000  0.096532  0.000000  0.793814   \n1285  0.933333  0.337778  0.516760  0.014375  0.375145  0.000571  0.917526   \n\n            7         8         9         10        11        12        13  \\\n0     0.003271  0.214381  0.042381  0.614583  0.568899  0.627660  0.000000   \n1     0.012165  0.182423  0.052381  0.635417  0.584296  0.627660  0.000000   \n2     0.015140  0.169108  0.055238  0.572917  0.515012  0.563830  0.000000   \n3     0.008681  0.175766  0.053810  0.625000  0.461124  0.617021  0.000000   \n4     0.009860  0.162450  0.056190  0.572917  0.612779  0.563830  0.000000   \n...        ...       ...       ...       ...       ...       ...       ...   \n1281  0.073767  0.364847  0.020952  0.895833  0.356428  0.893617  0.308911   \n1282  0.000000  0.023968  0.017143  0.958333  0.472671  0.957447  0.132673   \n1283  0.007593  0.328895  0.019524  0.041667  0.444958  0.670213  0.724752   \n1284  0.011283  0.312916  0.018571  0.781250  0.489607  0.776596  0.859406   \n1285  0.000000  0.390146  0.016190  0.927083  0.438799  0.914894  0.122772   \n\n            14        15        16        17        18        19  \n0     0.005254  0.024525  0.649446  0.626335  0.502137  0.347561  \n1     0.003086  0.002110  0.690037  0.669039  0.462607  0.274390  \n2     0.002240  0.002001  0.704797  0.683274  0.432692  0.237805  \n3     0.003056  0.020572  0.697417  0.676157  0.443376  0.256098  \n4     0.000165  0.000199  0.708487  0.690391  0.423077  0.225610  \n...        ...       ...       ...       ...       ...       ...  \n1281  0.005941  0.001149  0.258303  0.245552  0.465812  0.353659  \n1282  0.000886  0.000120  0.225092  0.209964  0.521368  0.378049  \n1283  0.003757  0.009764  0.357934  0.348754  0.446581  0.323171  \n1284  0.004546  0.009446  0.402214  0.395018  0.463675  0.341463  \n1285  0.001022  0.011911  0.214022  0.199288  0.532051  0.371951  \n\n[1286 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.866667</td>\n      <td>0.353333</td>\n      <td>0.372905</td>\n      <td>0.041250</td>\n      <td>0.000000</td>\n      <td>0.003861</td>\n      <td>0.639175</td>\n      <td>0.003271</td>\n      <td>0.214381</td>\n      <td>0.042381</td>\n      <td>0.614583</td>\n      <td>0.568899</td>\n      <td>0.627660</td>\n      <td>0.000000</td>\n      <td>0.005254</td>\n      <td>0.024525</td>\n      <td>0.649446</td>\n      <td>0.626335</td>\n      <td>0.502137</td>\n      <td>0.347561</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.533333</td>\n      <td>0.313333</td>\n      <td>0.399441</td>\n      <td>0.050000</td>\n      <td>0.001156</td>\n      <td>0.001365</td>\n      <td>0.639175</td>\n      <td>0.012165</td>\n      <td>0.182423</td>\n      <td>0.052381</td>\n      <td>0.635417</td>\n      <td>0.584296</td>\n      <td>0.627660</td>\n      <td>0.000000</td>\n      <td>0.003086</td>\n      <td>0.002110</td>\n      <td>0.690037</td>\n      <td>0.669039</td>\n      <td>0.462607</td>\n      <td>0.274390</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.400000</td>\n      <td>0.295556</td>\n      <td>0.410615</td>\n      <td>0.052500</td>\n      <td>0.001156</td>\n      <td>0.000906</td>\n      <td>0.639175</td>\n      <td>0.015140</td>\n      <td>0.169108</td>\n      <td>0.055238</td>\n      <td>0.572917</td>\n      <td>0.515012</td>\n      <td>0.563830</td>\n      <td>0.000000</td>\n      <td>0.002240</td>\n      <td>0.002001</td>\n      <td>0.704797</td>\n      <td>0.683274</td>\n      <td>0.432692</td>\n      <td>0.237805</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.466667</td>\n      <td>0.300000</td>\n      <td>0.410615</td>\n      <td>0.051250</td>\n      <td>0.000578</td>\n      <td>0.000575</td>\n      <td>0.628866</td>\n      <td>0.008681</td>\n      <td>0.175766</td>\n      <td>0.053810</td>\n      <td>0.625000</td>\n      <td>0.461124</td>\n      <td>0.617021</td>\n      <td>0.000000</td>\n      <td>0.003056</td>\n      <td>0.020572</td>\n      <td>0.697417</td>\n      <td>0.676157</td>\n      <td>0.443376</td>\n      <td>0.256098</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.333333</td>\n      <td>0.295556</td>\n      <td>0.405028</td>\n      <td>0.053125</td>\n      <td>0.000578</td>\n      <td>0.000073</td>\n      <td>0.659794</td>\n      <td>0.009860</td>\n      <td>0.162450</td>\n      <td>0.056190</td>\n      <td>0.572917</td>\n      <td>0.612779</td>\n      <td>0.563830</td>\n      <td>0.000000</td>\n      <td>0.000165</td>\n      <td>0.000199</td>\n      <td>0.708487</td>\n      <td>0.690391</td>\n      <td>0.423077</td>\n      <td>0.225610</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1281</th>\n      <td>0.666667</td>\n      <td>0.186667</td>\n      <td>0.734637</td>\n      <td>0.018125</td>\n      <td>0.300578</td>\n      <td>0.002811</td>\n      <td>0.072165</td>\n      <td>0.073767</td>\n      <td>0.364847</td>\n      <td>0.020952</td>\n      <td>0.895833</td>\n      <td>0.356428</td>\n      <td>0.893617</td>\n      <td>0.308911</td>\n      <td>0.005941</td>\n      <td>0.001149</td>\n      <td>0.258303</td>\n      <td>0.245552</td>\n      <td>0.465812</td>\n      <td>0.353659</td>\n    </tr>\n    <tr>\n      <th>1282</th>\n      <td>0.866667</td>\n      <td>0.311111</td>\n      <td>0.555866</td>\n      <td>0.015625</td>\n      <td>0.368786</td>\n      <td>0.000563</td>\n      <td>0.958763</td>\n      <td>0.000000</td>\n      <td>0.023968</td>\n      <td>0.017143</td>\n      <td>0.958333</td>\n      <td>0.472671</td>\n      <td>0.957447</td>\n      <td>0.132673</td>\n      <td>0.000886</td>\n      <td>0.000120</td>\n      <td>0.225092</td>\n      <td>0.209964</td>\n      <td>0.521368</td>\n      <td>0.378049</td>\n    </tr>\n    <tr>\n      <th>1283</th>\n      <td>0.200000</td>\n      <td>0.011111</td>\n      <td>0.997207</td>\n      <td>0.016250</td>\n      <td>0.234104</td>\n      <td>0.000000</td>\n      <td>0.051546</td>\n      <td>0.007593</td>\n      <td>0.328895</td>\n      <td>0.019524</td>\n      <td>0.041667</td>\n      <td>0.444958</td>\n      <td>0.670213</td>\n      <td>0.724752</td>\n      <td>0.003757</td>\n      <td>0.009764</td>\n      <td>0.357934</td>\n      <td>0.348754</td>\n      <td>0.446581</td>\n      <td>0.323171</td>\n    </tr>\n    <tr>\n      <th>1284</th>\n      <td>0.000000</td>\n      <td>0.044444</td>\n      <td>0.927374</td>\n      <td>0.015000</td>\n      <td>0.096532</td>\n      <td>0.000000</td>\n      <td>0.793814</td>\n      <td>0.011283</td>\n      <td>0.312916</td>\n      <td>0.018571</td>\n      <td>0.781250</td>\n      <td>0.489607</td>\n      <td>0.776596</td>\n      <td>0.859406</td>\n      <td>0.004546</td>\n      <td>0.009446</td>\n      <td>0.402214</td>\n      <td>0.395018</td>\n      <td>0.463675</td>\n      <td>0.341463</td>\n    </tr>\n    <tr>\n      <th>1285</th>\n      <td>0.933333</td>\n      <td>0.337778</td>\n      <td>0.516760</td>\n      <td>0.014375</td>\n      <td>0.375145</td>\n      <td>0.000571</td>\n      <td>0.917526</td>\n      <td>0.000000</td>\n      <td>0.390146</td>\n      <td>0.016190</td>\n      <td>0.927083</td>\n      <td>0.438799</td>\n      <td>0.914894</td>\n      <td>0.122772</td>\n      <td>0.001022</td>\n      <td>0.011911</td>\n      <td>0.214022</td>\n      <td>0.199288</td>\n      <td>0.532051</td>\n      <td>0.371951</td>\n    </tr>\n  </tbody>\n</table>\n<p>1286 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 541,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "id": "692ae868",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "           0         1         2         3         4         5         6   \\\n0    0.000000  0.246085  0.436288  0.058667  0.000000  0.000855  0.628866   \n1    0.166667  0.277405  0.407202  0.058000  0.000000  0.000896  0.649485   \n2    0.083333  0.266219  0.002770  0.058667  0.000000  0.001365  0.639175   \n3    0.916667  0.340045  0.375346  0.046000  0.000000  0.006319  0.670103   \n4    0.000000  0.655481  0.018006  0.000667  0.237402  0.007776  0.969072   \n..        ...       ...       ...       ...       ...       ...       ...   \n357  0.500000  0.185682  0.673130  0.021333  0.115901  0.000877  0.061856   \n358  0.416667  0.306488  0.727147  0.022000  0.125420  0.000150  0.814433   \n359  0.000000  0.022371  0.948753  0.016667  0.095745  0.000000  0.762887   \n360  0.083333  0.011186  0.099723  0.016667  0.247480  0.000000  0.731959   \n361  0.250000  0.000000  1.000000  0.018000  0.243561  0.000000  0.680412   \n\n           7         8       9         10        11        12        13  \\\n0    0.098491  0.151515  0.0610  0.311828  0.504138  0.305263  0.000000   \n1    0.008970  0.163059  0.0610  0.376344  0.580888  0.389474  0.000000   \n2    0.027945  0.157287  0.0610  0.322581  0.501129  0.336842  0.000000   \n3    0.031328  0.223665  0.0465  0.655914  0.558315  0.663158  0.000000   \n4    0.000202  0.633478  0.0005  0.978495  0.368698  0.978947  0.000000   \n..        ...       ...     ...       ...       ...       ...       ...   \n357  0.006014  0.246753  0.0255  0.763441  0.246050  0.042105  0.268924   \n358  0.005160  0.240981  0.0260  0.827957  0.376975  0.810526  0.314741   \n359  0.005946  0.343434  0.0195  0.752688  0.380737  0.747368  0.836653   \n360  0.003417  0.349206  0.0200  0.720430  0.408578  0.705263  0.790837   \n361  0.000348  0.360750  0.0210  0.655914  0.453725  0.642105  0.667331   \n\n           14        15        16        17        18        19  \n0    0.001530  0.002515  0.073801  0.082143  0.369164  0.086420  \n1    0.002602  0.002005  0.723247  0.707143  0.404995  0.123457  \n2    0.002459  0.018632  0.730627  0.075000  0.370250  0.104938  \n3    0.008826  0.003134  0.656827  0.639286  0.502714  0.327160  \n4    0.017504  0.000031  0.073801  0.071429  0.718784  0.376543  \n..        ...       ...       ...       ...       ...       ...  \n357  0.001491  0.010788  0.250923  0.239286  0.534202  0.407407  \n358  0.000152  0.010497  0.254613  0.242857  0.520087  0.395062  \n359  0.007223  0.010483  0.055351  0.057143  0.463626  0.327160  \n360  0.000735  0.000106  0.040590  0.042857  0.463626  0.339506  \n361  0.005979  0.010831  0.343173  0.332143  0.441911  0.290123  \n\n[362 rows x 20 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>10</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.000000</td>\n      <td>0.246085</td>\n      <td>0.436288</td>\n      <td>0.058667</td>\n      <td>0.000000</td>\n      <td>0.000855</td>\n      <td>0.628866</td>\n      <td>0.098491</td>\n      <td>0.151515</td>\n      <td>0.0610</td>\n      <td>0.311828</td>\n      <td>0.504138</td>\n      <td>0.305263</td>\n      <td>0.000000</td>\n      <td>0.001530</td>\n      <td>0.002515</td>\n      <td>0.073801</td>\n      <td>0.082143</td>\n      <td>0.369164</td>\n      <td>0.086420</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.166667</td>\n      <td>0.277405</td>\n      <td>0.407202</td>\n      <td>0.058000</td>\n      <td>0.000000</td>\n      <td>0.000896</td>\n      <td>0.649485</td>\n      <td>0.008970</td>\n      <td>0.163059</td>\n      <td>0.0610</td>\n      <td>0.376344</td>\n      <td>0.580888</td>\n      <td>0.389474</td>\n      <td>0.000000</td>\n      <td>0.002602</td>\n      <td>0.002005</td>\n      <td>0.723247</td>\n      <td>0.707143</td>\n      <td>0.404995</td>\n      <td>0.123457</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.083333</td>\n      <td>0.266219</td>\n      <td>0.002770</td>\n      <td>0.058667</td>\n      <td>0.000000</td>\n      <td>0.001365</td>\n      <td>0.639175</td>\n      <td>0.027945</td>\n      <td>0.157287</td>\n      <td>0.0610</td>\n      <td>0.322581</td>\n      <td>0.501129</td>\n      <td>0.336842</td>\n      <td>0.000000</td>\n      <td>0.002459</td>\n      <td>0.018632</td>\n      <td>0.730627</td>\n      <td>0.075000</td>\n      <td>0.370250</td>\n      <td>0.104938</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.916667</td>\n      <td>0.340045</td>\n      <td>0.375346</td>\n      <td>0.046000</td>\n      <td>0.000000</td>\n      <td>0.006319</td>\n      <td>0.670103</td>\n      <td>0.031328</td>\n      <td>0.223665</td>\n      <td>0.0465</td>\n      <td>0.655914</td>\n      <td>0.558315</td>\n      <td>0.663158</td>\n      <td>0.000000</td>\n      <td>0.008826</td>\n      <td>0.003134</td>\n      <td>0.656827</td>\n      <td>0.639286</td>\n      <td>0.502714</td>\n      <td>0.327160</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.000000</td>\n      <td>0.655481</td>\n      <td>0.018006</td>\n      <td>0.000667</td>\n      <td>0.237402</td>\n      <td>0.007776</td>\n      <td>0.969072</td>\n      <td>0.000202</td>\n      <td>0.633478</td>\n      <td>0.0005</td>\n      <td>0.978495</td>\n      <td>0.368698</td>\n      <td>0.978947</td>\n      <td>0.000000</td>\n      <td>0.017504</td>\n      <td>0.000031</td>\n      <td>0.073801</td>\n      <td>0.071429</td>\n      <td>0.718784</td>\n      <td>0.376543</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>357</th>\n      <td>0.500000</td>\n      <td>0.185682</td>\n      <td>0.673130</td>\n      <td>0.021333</td>\n      <td>0.115901</td>\n      <td>0.000877</td>\n      <td>0.061856</td>\n      <td>0.006014</td>\n      <td>0.246753</td>\n      <td>0.0255</td>\n      <td>0.763441</td>\n      <td>0.246050</td>\n      <td>0.042105</td>\n      <td>0.268924</td>\n      <td>0.001491</td>\n      <td>0.010788</td>\n      <td>0.250923</td>\n      <td>0.239286</td>\n      <td>0.534202</td>\n      <td>0.407407</td>\n    </tr>\n    <tr>\n      <th>358</th>\n      <td>0.416667</td>\n      <td>0.306488</td>\n      <td>0.727147</td>\n      <td>0.022000</td>\n      <td>0.125420</td>\n      <td>0.000150</td>\n      <td>0.814433</td>\n      <td>0.005160</td>\n      <td>0.240981</td>\n      <td>0.0260</td>\n      <td>0.827957</td>\n      <td>0.376975</td>\n      <td>0.810526</td>\n      <td>0.314741</td>\n      <td>0.000152</td>\n      <td>0.010497</td>\n      <td>0.254613</td>\n      <td>0.242857</td>\n      <td>0.520087</td>\n      <td>0.395062</td>\n    </tr>\n    <tr>\n      <th>359</th>\n      <td>0.000000</td>\n      <td>0.022371</td>\n      <td>0.948753</td>\n      <td>0.016667</td>\n      <td>0.095745</td>\n      <td>0.000000</td>\n      <td>0.762887</td>\n      <td>0.005946</td>\n      <td>0.343434</td>\n      <td>0.0195</td>\n      <td>0.752688</td>\n      <td>0.380737</td>\n      <td>0.747368</td>\n      <td>0.836653</td>\n      <td>0.007223</td>\n      <td>0.010483</td>\n      <td>0.055351</td>\n      <td>0.057143</td>\n      <td>0.463626</td>\n      <td>0.327160</td>\n    </tr>\n    <tr>\n      <th>360</th>\n      <td>0.083333</td>\n      <td>0.011186</td>\n      <td>0.099723</td>\n      <td>0.016667</td>\n      <td>0.247480</td>\n      <td>0.000000</td>\n      <td>0.731959</td>\n      <td>0.003417</td>\n      <td>0.349206</td>\n      <td>0.0200</td>\n      <td>0.720430</td>\n      <td>0.408578</td>\n      <td>0.705263</td>\n      <td>0.790837</td>\n      <td>0.000735</td>\n      <td>0.000106</td>\n      <td>0.040590</td>\n      <td>0.042857</td>\n      <td>0.463626</td>\n      <td>0.339506</td>\n    </tr>\n    <tr>\n      <th>361</th>\n      <td>0.250000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.018000</td>\n      <td>0.243561</td>\n      <td>0.000000</td>\n      <td>0.680412</td>\n      <td>0.000348</td>\n      <td>0.360750</td>\n      <td>0.0210</td>\n      <td>0.655914</td>\n      <td>0.453725</td>\n      <td>0.642105</td>\n      <td>0.667331</td>\n      <td>0.005979</td>\n      <td>0.010831</td>\n      <td>0.343173</td>\n      <td>0.332143</td>\n      <td>0.441911</td>\n      <td>0.290123</td>\n    </tr>\n  </tbody>\n</table>\n<p>362 rows × 20 columns</p>\n</div>"
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "id": "important-grove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.35333333, 0.31333333, 0.29555556, ..., 0.01111111, 0.04444444,\n       0.33777778])"
     },
     "execution_count": 543,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate training X and Y values\n",
    "train_X = training_data.iloc[:, 2:20].values\n",
    "train_Y = training_data.iloc[:, 1].values\n",
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "24b2aa58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.37290503, 0.04125   , 0.        , ..., 0.62633452, 0.50213675,\n        0.34756098],\n       [0.39944134, 0.05      , 0.00115607, ..., 0.66903915, 0.46260684,\n        0.27439024],\n       [0.41061453, 0.0525    , 0.00115607, ..., 0.68327402, 0.43269231,\n        0.23780488],\n       ...,\n       [0.9972067 , 0.01625   , 0.23410405, ..., 0.34875445, 0.4465812 ,\n        0.32317073],\n       [0.9273743 , 0.015     , 0.09653179, ..., 0.39501779, 0.46367521,\n        0.34146341],\n       [0.51675978, 0.014375  , 0.37514451, ..., 0.19928826, 0.53205128,\n        0.37195122]])"
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we do not include the year column\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.24608501, 0.27740492, 0.26621924, 0.34004474, 0.65548098,\n       0.63758389, 0.64876957, 0.72930649, 0.63982103, 0.65100671,\n       0.65995526, 0.11856823, 0.10738255, 0.66666667, 0.68008949,\n       0.68456376, 0.63310962, 0.63310962, 0.64205817, 0.79642058,\n       0.93288591, 0.82102908, 0.76733781, 0.76957494, 0.78299776,\n       0.52572707, 0.53914989, 0.53914989, 0.51454139, 0.52572707,\n       0.53467562, 0.52348993, 0.51230425, 0.53467562, 0.75391499,\n       0.75391499, 0.77181208, 0.53467562, 0.54138702, 0.5458613 ,\n       0.25727069, 0.2639821 , 0.27293065, 0.38926174, 0.40715884,\n       0.44519016, 0.68680089, 0.70246085, 0.69574944, 0.05369128,\n       0.03803132, 0.08501119, 0.59731544, 0.60626398, 0.6196868 ,\n       0.61073826, 0.61521253, 0.62416107, 0.29530201, 0.2639821 ,\n       0.20357942, 0.21923937, 0.23489933, 0.59955257, 0.60626398,\n       0.61521253, 0.49888143, 0.47651007, 0.20805369, 0.20134228,\n       0.79865772, 0.82102908, 0.91051454, 0.10961969, 0.19463087,\n       0.16778523, 0.28411633, 0.77852349, 0.78970917, 0.62416107,\n       0.63534676, 0.65324385, 0.60850112, 0.61521253, 0.63758389,\n       0.34675615, 0.35123043, 0.41834452, 0.74272931, 0.7606264 ,\n       0.74720358, 0.72259508, 0.71588367, 0.75838926, 0.76286353,\n       0.76733781, 0.3803132 , 0.55257271, 0.60178971, 0.60626398,\n       0.55928412, 0.65100671, 0.65548098, 0.67337808, 0.55033557,\n       0.64205817, 0.57494407, 0.3310962 , 0.32438479, 0.63758389,\n       0.64205817, 0.64205817, 0.39149888, 0.53020134, 0.52572707,\n       0.52796421, 0.53243848, 0.77628635, 0.78076063, 0.84340045,\n       0.38702461, 0.38255034, 0.64205817, 0.61297539, 0.62639821,\n       0.7606264 , 0.76286353, 0.77852349, 0.30425056, 0.31319911,\n       0.32662192, 0.76957494, 0.77628635, 0.78076063, 0.68680089,\n       0.56823266, 0.30201342, 0.29082774, 0.27740492, 0.29753915,\n       0.46979866, 0.46532438, 0.46308725, 0.41163311, 0.60402685,\n       0.61073826, 0.62416107, 0.44966443, 0.45861298, 0.46756152,\n       0.4966443 , 0.50111857, 0.46979866, 0.5033557 , 0.45637584,\n       0.48322148, 0.88814318, 0.78299776, 0.78299776, 0.82102908,\n       0.79418345, 0.79865772, 1.        , 0.64876957, 0.65324385,\n       0.66442953, 0.61744966, 0.62192394, 0.63087248, 0.44966443,\n       0.45637584, 0.45637584, 0.18120805, 0.19463087, 0.21923937,\n       0.44742729, 0.4541387 , 0.45861298, 0.57270694, 0.64205817,\n       0.59731544, 0.64205817, 0.64653244, 0.65771812, 0.01118568,\n       0.00447427, 0.02237136, 0.50782998, 0.33333333, 0.60178971,\n       0.60626398, 0.61073826, 0.75391499, 0.7606264 , 0.76957494,\n       0.34899329, 0.44071588, 0.55257271, 0.00671141, 0.01789709,\n       0.03803132, 0.63534676, 0.63982103, 0.64653244, 0.75391499,\n       0.61521253, 0.65100671, 0.1901566 , 0.20805369, 0.22371365,\n       0.76957494, 0.77628635, 0.78299776, 0.37807606, 0.55257271,\n       0.60850112, 0.60850112, 0.61744966, 0.68680089, 0.68680089,\n       0.69574944, 0.42281879, 0.43624161, 0.44071588, 0.6935123 ,\n       0.67785235, 0.55257271, 0.56375839, 0.6196868 , 0.12304251,\n       0.21700224, 0.3064877 , 0.4295302 , 0.43847875, 0.44519016,\n       0.44742729, 0.45637584, 0.47203579, 0.48545861, 0.82326622,\n       0.64205817, 0.68680089, 0.59731544, 0.31096197, 0.41834452,\n       0.2393736 , 0.12304251, 0.43400447, 0.41610738, 0.44519016,\n       0.70246085, 0.70469799, 0.70469799, 0.3310962 , 0.33557047,\n       0.34899329, 0.61744966, 0.62192394, 0.62639821, 0.62416107,\n       0.63758389, 0.6689038 , 0.5033557 , 0.5033557 , 0.51454139,\n       0.6689038 , 0.67561521, 0.68456376, 0.72930649, 0.7360179 ,\n       0.75391499, 0.75391499, 0.73154362, 0.61297539, 0.45861298,\n       0.46085011, 0.46308725, 0.17225951, 0.20357942, 0.24608501,\n       0.68680089, 0.70917226, 0.60626398, 0.43624161, 0.44742729,\n       0.45637584, 0.46308725, 0.3803132 , 0.39821029, 0.64205817,\n       0.65548098, 0.65995526, 0.6196868 , 0.62192394, 0.62192394,\n       0.08501119, 0.06263982, 0.48993289, 0.4966443 , 0.51006711,\n       0.26174497, 0.23713647, 0.21029083, 0.7852349 , 0.78747204,\n       0.82102908, 0.55480984, 0.6689038 , 0.65995526, 0.56375839,\n       0.55928412, 0.06263982, 0.04697987, 0.02908277, 0.83668904,\n       0.64205817, 0.63758389, 0.46756152, 0.48322148, 0.47427293,\n       0.60178971, 0.60626398, 0.61073826, 0.51677852, 0.49888143,\n       0.32662192, 0.27740492, 0.61521253, 0.61744966, 0.62416107,\n       0.55928412, 0.56152125, 0.56375839, 0.64653244, 0.65324385,\n       0.66442953, 0.75391499, 0.60178971, 0.6196868 , 0.42729306,\n       0.4295302 , 0.42505593, 0.14988814, 0.15659955, 0.19910515,\n       0.52348993, 0.5212528 , 0.51677852, 0.69127517, 0.69574944,\n       0.69574944, 0.51230425, 0.52572707, 0.51454139, 0.55480984,\n       0.55928412, 0.56599553, 0.18568233, 0.3064877 , 0.02237136,\n       0.01118568, 0.        ])"
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load testing values\n",
    "test_X = testing_data.iloc[:, 2:20].values\n",
    "test_Y = testing_data.iloc[:, 1].values\n",
    "test_Y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[0.43628809, 0.05866667, 0.        , ..., 0.08214286, 0.36916395,\n        0.08641975],\n       [0.40720222, 0.058     , 0.        , ..., 0.70714286, 0.40499457,\n        0.12345679],\n       [0.00277008, 0.05866667, 0.        , ..., 0.075     , 0.37024973,\n        0.10493827],\n       ...,\n       [0.94875346, 0.01666667, 0.09574468, ..., 0.05714286, 0.46362649,\n        0.32716049],\n       [0.09972299, 0.01666667, 0.2474804 , ..., 0.04285714, 0.46362649,\n        0.33950617],\n       [1.        , 0.018     , 0.24356103, ..., 0.33214286, 0.44191097,\n        0.29012346]])"
     },
     "execution_count": 546,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  0.23\n"
     ]
    }
   ],
   "source": [
    "#basline estimate\n",
    "#getting life_expectancy from the oroginal testing data\n",
    "baseline_preds = testing_data.iloc[:, 1:2].values\n",
    "# print(baseline_preds)\n",
    "# Baseline errors, and display average baseline error\n",
    "base_errors = abs(baseline_preds - test_Y)\n",
    "print('Average baseline error: ', round(np.mean(base_errors), 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "id": "cef65bf4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27432113 0.28741071 0.50364543 0.34763804 0.65524013 0.65164582\n",
      " 0.65519875 0.72095837 0.62202234 0.63061901 0.64834506 0.1977831\n",
      " 0.20452007 0.68242391 0.72536107 0.69839346 0.6360804  0.64248028\n",
      " 0.6457303  0.88187601 0.85764637 0.84517318 0.78456749 0.81984695\n",
      " 0.80930356 0.61446359 0.62111073 0.61863256 0.49795939 0.528387\n",
      " 0.53876645 0.54140211 0.54357176 0.54977158 0.83493143 0.80764185\n",
      " 0.84036066 0.56232789 0.56203422 0.57510372 0.26631909 0.27026236\n",
      " 0.28373608 0.52181158 0.40348499 0.42117441 0.61940616 0.65362638\n",
      " 0.6623793  0.14866518 0.12192817 0.19807997 0.63126696 0.65107995\n",
      " 0.65685957 0.65264275 0.64270981 0.64248755 0.3214128  0.28750197\n",
      " 0.24896051 0.25007433 0.23539888 0.62026175 0.61593507 0.6130252\n",
      " 0.50214364 0.46337555 0.24922737 0.23972137 0.85333636 0.8793793\n",
      " 0.88512525 0.1296759  0.17600354 0.17876471 0.21312492 0.79804222\n",
      " 0.80273531 0.61740098 0.62935802 0.63225225 0.62597006 0.63497166\n",
      " 0.64722142 0.39122479 0.39083687 0.40181215 0.69151477 0.69788077\n",
      " 0.72791494 0.75898498 0.76001368 0.77949706 0.78188843 0.79993229\n",
      " 0.40114971 0.39812244 0.58762139 0.5865653  0.55067437 0.63585084\n",
      " 0.65135938 0.66187306 0.55745313 0.5982915  0.5829758  0.31888191\n",
      " 0.31127432 0.68471757 0.68345215 0.68771355 0.32859994 0.31672593\n",
      " 0.54180332 0.56573829 0.5587381  0.83596251 0.84890408 0.88826604\n",
      " 0.38773344 0.38752879 0.64096373 0.6407934  0.66545293 0.84991555\n",
      " 0.84609366 0.83084549 0.26612611 0.30281217 0.34059736 0.79760193\n",
      " 0.8123179  0.81335904 0.6325322  0.61232397 0.29061831 0.24502322\n",
      " 0.28906364 0.29802789 0.48230372 0.48520536 0.48633313 0.41892755\n",
      " 0.59412068 0.60934131 0.63137571 0.46239289 0.51240754 0.50852712\n",
      " 0.51522012 0.5166401  0.51434975 0.56558671 0.50531833 0.52631878\n",
      " 0.85543403 0.86069969 0.86076817 0.84409309 0.83275103 0.84848071\n",
      " 0.85185363 0.64037637 0.65798929 0.67168272 0.64696206 0.64613159\n",
      " 0.64847779 0.4757745  0.49028169 0.49207294 0.16322831 0.16542176\n",
      " 0.2061061  0.48670455 0.49112711 0.49378026 0.57943844 0.58606688\n",
      " 0.67615541 0.63342298 0.62290292 0.63933316 0.05277282 0.0767716\n",
      " 0.07654777 0.35457185 0.3377529  0.63782721 0.63190542 0.63812142\n",
      " 0.79996476 0.80153417 0.84298433 0.34959897 0.3697714  0.40231493\n",
      " 0.06967474 0.08317188 0.10239013 0.64254361 0.64801593 0.66212785\n",
      " 0.63284629 0.63727394 0.65153533 0.25989157 0.27232424 0.2694089\n",
      " 0.8004808  0.86304815 0.85035714 0.41071688 0.41856785 0.6163814\n",
      " 0.60034955 0.63286576 0.68929513 0.69010429 0.70649339 0.45779252\n",
      " 0.46502465 0.45737689 0.7009641  0.68072762 0.55795468 0.58220238\n",
      " 0.63058273 0.17323257 0.17263379 0.16142051 0.45433065 0.44606034\n",
      " 0.46177841 0.4330425  0.47690518 0.49117195 0.52661836 0.84518215\n",
      " 0.59338186 0.60910518 0.59196882 0.32621433 0.35857853 0.22267704\n",
      " 0.16998305 0.46905647 0.49319126 0.47654778 0.68558313 0.68679078\n",
      " 0.69713323 0.36931251 0.37539029 0.37979421 0.63149063 0.63794355\n",
      " 0.64107666 0.66342043 0.66785336 0.67364675 0.51330137 0.5162146\n",
      " 0.52630735 0.67474079 0.68094084 0.67657897 0.74659597 0.75260579\n",
      " 0.76722285 0.62096708 0.62521183 0.62613655 0.51487755 0.50957684\n",
      " 0.51244642 0.25690058 0.26163013 0.26152422 0.66711391 0.66492281\n",
      " 0.63672644 0.43387947 0.43076459 0.46886496 0.39475652 0.40443771\n",
      " 0.40704778 0.66863708 0.66739835 0.66848964 0.60930358 0.61831738\n",
      " 0.61368531 0.18346661 0.18241674 0.50417915 0.52269124 0.53935996\n",
      " 0.2770032  0.26855738 0.24089268 0.81893869 0.83931568 0.87294752\n",
      " 0.5805349  0.66336273 0.66195996 0.59769216 0.56655321 0.08194775\n",
      " 0.0854421  0.08570585 0.86057268 0.64083384 0.63531004 0.50934564\n",
      " 0.51949113 0.50659552 0.57253201 0.57557488 0.59305479 0.53987242\n",
      " 0.52019556 0.35283037 0.32308158 0.63922407 0.64203087 0.64236716\n",
      " 0.5742519  0.60413014 0.60329827 0.65506933 0.63224776 0.6592121\n",
      " 0.6351915  0.64806223 0.6454324  0.47299474 0.47195396 0.44100973\n",
      " 0.22170295 0.20703614 0.2230022  0.53328284 0.53013617 0.53455779\n",
      " 0.70934776 0.70706904 0.72019711 0.53368315 0.53967883 0.5297154\n",
      " 0.54228492 0.55617228 0.57059826 0.16964875 0.16035339 0.07820528\n",
      " 0.10707542 0.03657034]\n"
     ]
    }
   ],
   "source": [
    "#Training Model using RandomForestRegressor\n",
    "regressor = RandomForestRegressor(n_estimators = 300, max_leaf_nodes = 300, bootstrap = True)\n",
    "# Fit the regressor with x and y data\n",
    "regressor.fit(train_X, train_Y)\n",
    "# Predict with testing X\n",
    "predict_Y = regressor.predict(test_X)\n",
    "print(predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "id": "8954ac93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.03 degrees.\n"
     ]
    }
   ],
   "source": [
    "# making prediction on the test set, we will get the prediction life expectancy\n",
    "predict_Y = regressor.predict(test_X)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predict_Y - test_Y)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "id": "ba1c2a22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 89.77 %.\n"
     ]
    }
   ],
   "source": [
    "#Determine Performance Metrics\n",
    "# Calculate mean absolute percentage error\n",
    "percentage_error = 100 * (errors / predict_Y)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(percentage_error)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "id": "eced860a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable:                   17 Importance: 0.57\n",
      "Variable:                   12 Importance: 0.23\n",
      "Variable:                    1 Importance: 0.11\n",
      "Variable:                    3 Importance: 0.01\n",
      "Variable:                    7 Importance: 0.01\n",
      "Variable:                   10 Importance: 0.01\n",
      "Variable:                   15 Importance: 0.01\n",
      "Variable:                   16 Importance: 0.01\n",
      "Variable:                   18 Importance: 0.01\n",
      "Variable:                    2 Importance: 0.0\n",
      "Variable:                    4 Importance: 0.0\n",
      "Variable:                    5 Importance: 0.0\n",
      "Variable:                    6 Importance: 0.0\n",
      "Variable:                    8 Importance: 0.0\n",
      "Variable:                    9 Importance: 0.0\n",
      "Variable:                   11 Importance: 0.0\n",
      "Variable:                   13 Importance: 0.0\n",
      "Variable:                   14 Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "#figuring out the usefulness of all the variable in the entire random forest\n",
    "# Get numerical feature importances\n",
    "testing_data_without_year = testing_data.drop(testing_data.columns[[0]],axis = 1)\n",
    "# print(testing_data_without_year)\n",
    "importances = list(regressor.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(testing_data_without_year, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "0356118d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#picking up the most important variables to recalculate the importance\n",
    "updated_testing = testing_data.iloc[:, [1,3,7,10,15,16,18,12,17]]\n",
    "test_important = testing_data.iloc[:, [1,3,7,10,15,16,18,12,17]].values\n",
    "train_important = training_data.iloc[:, [1,3,7,10,15,16,18,12,17]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "id": "3cd56408",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable:                    1 Importance: 0.11\n",
      "Variable:                    7 Importance: 0.01\n",
      "Variable:                   18 Importance: 0.01\n",
      "Variable:                    3 Importance: 0.0\n",
      "Variable:                   10 Importance: 0.0\n",
      "Variable:                   15 Importance: 0.0\n",
      "Variable:                   16 Importance: 0.0\n",
      "Variable:                   12 Importance: 0.0\n",
      "Variable:                   17 Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "updated_importances = list(regressor.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(updated_testing, updated_importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "id": "9e27e732",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0009633447456132175 degrees.\n",
      "Accuracy: -inf %.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xu842\\AppData\\Local\\Temp\\ipykernel_54568\\2633863536.py:10: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  updated_error_percentage = np.mean(100 * (errors / test_Y))\n"
     ]
    }
   ],
   "source": [
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators = 300, max_leaf_nodes = 300, bootstrap = True)\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_Y)\n",
    "# Make predictions and determine the error\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "errors = abs(predictions - test_Y)\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', np.mean(errors), 'degrees.')\n",
    "updated_error_percentage = np.mean(100 * (errors / test_Y))\n",
    "accuracy = 100 - updated_error_percentage\n",
    "print('Accuracy:', accuracy, '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "id": "a985c98a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The number of FixedLocator locations (18), usually from a call to set_ticks, does not match the number of ticklabels (20).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [555]\u001B[0m, in \u001B[0;36m<cell line: 7>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(x_value)\n\u001B[0;32m      6\u001B[0m plt\u001B[38;5;241m.\u001B[39mbar(x_value, importances, orientation \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvertical\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 7\u001B[0m \u001B[43mplt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mxticks\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_value\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtesting_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrotation\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m6\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m plt\u001B[38;5;241m.\u001B[39mylabel(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mimportance\u001B[39m\u001B[38;5;124m'\u001B[39m);\n\u001B[0;32m     10\u001B[0m plt\u001B[38;5;241m.\u001B[39mxlable(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVariable\u001B[39m\u001B[38;5;124m'\u001B[39m);\n",
      "File \u001B[1;32mc:\\users\\xu842\\pycharmprojects\\leetcode2021python\\venv\\lib\\site-packages\\matplotlib\\pyplot.py:1816\u001B[0m, in \u001B[0;36mxticks\u001B[1;34m(ticks, labels, **kwargs)\u001B[0m\n\u001B[0;32m   1814\u001B[0m         l\u001B[38;5;241m.\u001B[39mupdate(kwargs)\n\u001B[0;32m   1815\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1816\u001B[0m     labels \u001B[38;5;241m=\u001B[39m ax\u001B[38;5;241m.\u001B[39mset_xticklabels(labels, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1818\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m locs, labels\n",
      "File \u001B[1;32mc:\\users\\xu842\\pycharmprojects\\leetcode2021python\\venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:75\u001B[0m, in \u001B[0;36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 75\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m get_method(\u001B[38;5;28mself\u001B[39m)(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\xu842\\pycharmprojects\\leetcode2021python\\venv\\lib\\site-packages\\matplotlib\\axis.py:1798\u001B[0m, in \u001B[0;36mAxis._set_ticklabels\u001B[1;34m(self, labels, fontdict, minor, **kwargs)\u001B[0m\n\u001B[0;32m   1796\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m fontdict \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   1797\u001B[0m     kwargs\u001B[38;5;241m.\u001B[39mupdate(fontdict)\n\u001B[1;32m-> 1798\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mset_ticklabels(labels, minor\u001B[38;5;241m=\u001B[39mminor, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mc:\\users\\xu842\\pycharmprojects\\leetcode2021python\\venv\\lib\\site-packages\\matplotlib\\axis.py:1720\u001B[0m, in \u001B[0;36mAxis.set_ticklabels\u001B[1;34m(self, ticklabels, minor, **kwargs)\u001B[0m\n\u001B[0;32m   1716\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(locator, mticker\u001B[38;5;241m.\u001B[39mFixedLocator):\n\u001B[0;32m   1717\u001B[0m     \u001B[38;5;66;03m# Passing [] as a list of ticklabels is often used as a way to\u001B[39;00m\n\u001B[0;32m   1718\u001B[0m     \u001B[38;5;66;03m# remove all tick labels, so only error for > 0 ticklabels\u001B[39;00m\n\u001B[0;32m   1719\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(locator\u001B[38;5;241m.\u001B[39mlocs) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mlen\u001B[39m(ticklabels) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(ticklabels) \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m-> 1720\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   1721\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe number of FixedLocator locations\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1722\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(locator\u001B[38;5;241m.\u001B[39mlocs)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m), usually from a call to\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1723\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m set_ticks, does not match\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1724\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m the number of ticklabels (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(ticklabels)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m).\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1725\u001B[0m     tickd \u001B[38;5;241m=\u001B[39m {loc: lab \u001B[38;5;28;01mfor\u001B[39;00m loc, lab \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(locator\u001B[38;5;241m.\u001B[39mlocs, ticklabels)}\n\u001B[0;32m   1726\u001B[0m     func \u001B[38;5;241m=\u001B[39m functools\u001B[38;5;241m.\u001B[39mpartial(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_with_dict, tickd)\n",
      "\u001B[1;31mValueError\u001B[0m: The number of FixedLocator locations (18), usually from a call to set_ticks, does not match the number of ticklabels (20)."
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_value = list(range(len(importances)))\n",
    "print(x_value)\n",
    "\n",
    "plt.bar(x_value, importances, orientation = 'vertical')\n",
    "plt.xticks(x_value, testing_data, rotation = 6)\n",
    "\n",
    "plt.ylabel('importance');\n",
    "plt.xlable('Variable');\n",
    "plt.title('Variable Importance');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "id": "meaningful-reading",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE loss on testing set: 0.0022961892637874508\n",
      "Random forest regressor score: 0.9453437982862909\n"
     ]
    }
   ],
   "source": [
    "errors = mean_squared_error(test_Y, predict_Y)\n",
    "print(\"MSE loss on testing set: \" + str(mean_squared_error(test_Y, predict_Y)))\n",
    "print(\"Random forest regressor score: \" + str(regressor.score(test_X, test_Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f84d1e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}