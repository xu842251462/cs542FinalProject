{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ideal-investor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make needed imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "from sklearn.tree import export_graphviz\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "naked-window",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>59.9</td>\n",
       "      <td>268</td>\n",
       "      <td>66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>73.219243</td>\n",
       "      <td>64</td>\n",
       "      <td>430</td>\n",
       "      <td>18.1</td>\n",
       "      <td>89</td>\n",
       "      <td>62</td>\n",
       "      <td>8.13</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>631.744976</td>\n",
       "      <td>31731688.0</td>\n",
       "      <td>17.7</td>\n",
       "      <td>17.7</td>\n",
       "      <td>0.470</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2008</td>\n",
       "      <td>58.1</td>\n",
       "      <td>287</td>\n",
       "      <td>80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>25.873925</td>\n",
       "      <td>64</td>\n",
       "      <td>1599</td>\n",
       "      <td>15.7</td>\n",
       "      <td>110</td>\n",
       "      <td>64</td>\n",
       "      <td>8.33</td>\n",
       "      <td>64</td>\n",
       "      <td>0.1</td>\n",
       "      <td>373.361116</td>\n",
       "      <td>2729431.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>18.9</td>\n",
       "      <td>0.433</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006</td>\n",
       "      <td>57.3</td>\n",
       "      <td>295</td>\n",
       "      <td>84</td>\n",
       "      <td>0.03</td>\n",
       "      <td>17.171518</td>\n",
       "      <td>64</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.7</td>\n",
       "      <td>116</td>\n",
       "      <td>58</td>\n",
       "      <td>7.43</td>\n",
       "      <td>58</td>\n",
       "      <td>0.1</td>\n",
       "      <td>272.563770</td>\n",
       "      <td>2589345.0</td>\n",
       "      <td>19.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.405</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2007</td>\n",
       "      <td>57.5</td>\n",
       "      <td>295</td>\n",
       "      <td>82</td>\n",
       "      <td>0.02</td>\n",
       "      <td>10.910156</td>\n",
       "      <td>63</td>\n",
       "      <td>1141</td>\n",
       "      <td>15.2</td>\n",
       "      <td>113</td>\n",
       "      <td>63</td>\n",
       "      <td>6.73</td>\n",
       "      <td>63</td>\n",
       "      <td>0.1</td>\n",
       "      <td>369.835796</td>\n",
       "      <td>26616792.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.415</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2005</td>\n",
       "      <td>57.3</td>\n",
       "      <td>291</td>\n",
       "      <td>85</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1.388648</td>\n",
       "      <td>66</td>\n",
       "      <td>1296</td>\n",
       "      <td>14.2</td>\n",
       "      <td>118</td>\n",
       "      <td>58</td>\n",
       "      <td>8.70</td>\n",
       "      <td>58</td>\n",
       "      <td>0.1</td>\n",
       "      <td>25.294130</td>\n",
       "      <td>257798.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.396</td>\n",
       "      <td>7.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010</td>\n",
       "      <td>52.4</td>\n",
       "      <td>527</td>\n",
       "      <td>29</td>\n",
       "      <td>5.21</td>\n",
       "      <td>53.308581</td>\n",
       "      <td>9</td>\n",
       "      <td>9696</td>\n",
       "      <td>29.4</td>\n",
       "      <td>44</td>\n",
       "      <td>89</td>\n",
       "      <td>5.37</td>\n",
       "      <td>89</td>\n",
       "      <td>15.7</td>\n",
       "      <td>713.635620</td>\n",
       "      <td>1486317.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.436</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>58.0</td>\n",
       "      <td>399</td>\n",
       "      <td>25</td>\n",
       "      <td>6.39</td>\n",
       "      <td>10.666707</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>3.8</td>\n",
       "      <td>36</td>\n",
       "      <td>95</td>\n",
       "      <td>6.88</td>\n",
       "      <td>95</td>\n",
       "      <td>6.8</td>\n",
       "      <td>111.227396</td>\n",
       "      <td>155456.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2003</td>\n",
       "      <td>44.5</td>\n",
       "      <td>715</td>\n",
       "      <td>26</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>998</td>\n",
       "      <td>26.7</td>\n",
       "      <td>41</td>\n",
       "      <td>7</td>\n",
       "      <td>6.52</td>\n",
       "      <td>68</td>\n",
       "      <td>36.7</td>\n",
       "      <td>453.351155</td>\n",
       "      <td>12633897.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>0.418</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>665</td>\n",
       "      <td>24</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>79</td>\n",
       "      <td>1483</td>\n",
       "      <td>25.5</td>\n",
       "      <td>39</td>\n",
       "      <td>78</td>\n",
       "      <td>7.10</td>\n",
       "      <td>78</td>\n",
       "      <td>43.5</td>\n",
       "      <td>547.358878</td>\n",
       "      <td>12222251.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.434</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>59.2</td>\n",
       "      <td>371</td>\n",
       "      <td>23</td>\n",
       "      <td>6.50</td>\n",
       "      <td>10.822595</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>31.3</td>\n",
       "      <td>34</td>\n",
       "      <td>92</td>\n",
       "      <td>6.44</td>\n",
       "      <td>91</td>\n",
       "      <td>6.3</td>\n",
       "      <td>127.474620</td>\n",
       "      <td>15411675.0</td>\n",
       "      <td>5.9</td>\n",
       "      <td>5.7</td>\n",
       "      <td>0.498</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1286 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1    2   3     4          5   6     7     8    9   10    11  12  \\\n",
       "2   2013  59.9  268  66  0.01  73.219243  64   430  18.1   89  62  8.13  64   \n",
       "7   2008  58.1  287  80  0.03  25.873925  64  1599  15.7  110  64  8.33  64   \n",
       "9   2006  57.3  295  84  0.03  17.171518  64  1990  14.7  116  58  7.43  58   \n",
       "8   2007  57.5  295  82  0.02  10.910156  63  1141  15.2  113  63  6.73  63   \n",
       "10  2005  57.3  291  85  0.02   1.388648  66  1296  14.2  118  58  8.70  58   \n",
       "..   ...   ...  ...  ..   ...        ...  ..   ...   ...  ...  ..   ...  ..   \n",
       "4   2010  52.4  527  29  5.21  53.308581   9  9696  29.4   44  89  5.37  89   \n",
       "1   2013  58.0  399  25  6.39  10.666707  95     0   3.8   36  95  6.88  95   \n",
       "11  2003  44.5  715  26  4.06   0.000000   7   998  26.7   41   7  6.52  68   \n",
       "14  2000  46.0  665  24  1.68   0.000000  79  1483  25.5   39  78  7.10  78   \n",
       "0   2014  59.2  371  23  6.50  10.822595  91     0  31.3   34  92  6.44  91   \n",
       "\n",
       "      13          14          15    16    17     18    19  \n",
       "2    0.1  631.744976  31731688.0  17.7  17.7  0.470   9.9  \n",
       "7    0.1  373.361116   2729431.0  18.8  18.9  0.433   8.7  \n",
       "9    0.1  272.563770   2589345.0  19.2  19.3  0.405   8.1  \n",
       "8    0.1  369.835796  26616792.0  19.0  19.1  0.415   8.4  \n",
       "10   0.1   25.294130    257798.0  19.3  19.5  0.396   7.9  \n",
       "..   ...         ...         ...   ...   ...    ...   ...  \n",
       "4   15.7  713.635620   1486317.0   7.1   7.0  0.436  10.0  \n",
       "1    6.8  111.227396    155456.0   6.2   6.0  0.488  10.4  \n",
       "11  36.7  453.351155  12633897.0   9.8   9.9  0.418   9.5  \n",
       "14  43.5  547.358878  12222251.0  11.0  11.2  0.434   9.8  \n",
       "0    6.3  127.474620  15411675.0   5.9   5.7  0.498  10.3  \n",
       "\n",
       "[1286 rows x 20 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load train and testing data\n",
    "training_data = pd.read_pickle(\"../data/train.pkl\")\n",
    "testing_data = pd.read_pickle(\"../data/test.pkl\")\n",
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "692ae868",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2001</td>\n",
       "      <td>55.3</td>\n",
       "      <td>316</td>\n",
       "      <td>88</td>\n",
       "      <td>0.01</td>\n",
       "      <td>10.574728</td>\n",
       "      <td>63</td>\n",
       "      <td>8762</td>\n",
       "      <td>12.6</td>\n",
       "      <td>122</td>\n",
       "      <td>35</td>\n",
       "      <td>7.80</td>\n",
       "      <td>33</td>\n",
       "      <td>0.1</td>\n",
       "      <td>117.496980</td>\n",
       "      <td>2966463.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>0.340</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003</td>\n",
       "      <td>56.7</td>\n",
       "      <td>295</td>\n",
       "      <td>87</td>\n",
       "      <td>0.01</td>\n",
       "      <td>11.089053</td>\n",
       "      <td>65</td>\n",
       "      <td>798</td>\n",
       "      <td>13.4</td>\n",
       "      <td>122</td>\n",
       "      <td>41</td>\n",
       "      <td>8.82</td>\n",
       "      <td>41</td>\n",
       "      <td>0.1</td>\n",
       "      <td>198.728544</td>\n",
       "      <td>2364851.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.373</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2002</td>\n",
       "      <td>56.2</td>\n",
       "      <td>3</td>\n",
       "      <td>88</td>\n",
       "      <td>0.01</td>\n",
       "      <td>16.887351</td>\n",
       "      <td>64</td>\n",
       "      <td>2486</td>\n",
       "      <td>13.0</td>\n",
       "      <td>122</td>\n",
       "      <td>36</td>\n",
       "      <td>7.76</td>\n",
       "      <td>36</td>\n",
       "      <td>0.1</td>\n",
       "      <td>187.845950</td>\n",
       "      <td>21979923.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.341</td>\n",
       "      <td>6.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012</td>\n",
       "      <td>59.5</td>\n",
       "      <td>272</td>\n",
       "      <td>69</td>\n",
       "      <td>0.01</td>\n",
       "      <td>78.184215</td>\n",
       "      <td>67</td>\n",
       "      <td>2787</td>\n",
       "      <td>17.6</td>\n",
       "      <td>93</td>\n",
       "      <td>67</td>\n",
       "      <td>8.52</td>\n",
       "      <td>67</td>\n",
       "      <td>0.1</td>\n",
       "      <td>669.959000</td>\n",
       "      <td>3696958.0</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2001</td>\n",
       "      <td>73.6</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>4.25</td>\n",
       "      <td>96.205571</td>\n",
       "      <td>96</td>\n",
       "      <td>18</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1</td>\n",
       "      <td>97</td>\n",
       "      <td>6.00</td>\n",
       "      <td>97</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1326.973390</td>\n",
       "      <td>36173.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2.1</td>\n",
       "      <td>0.662</td>\n",
       "      <td>10.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2007</td>\n",
       "      <td>52.6</td>\n",
       "      <td>487</td>\n",
       "      <td>32</td>\n",
       "      <td>2.08</td>\n",
       "      <td>10.851482</td>\n",
       "      <td>8</td>\n",
       "      <td>535</td>\n",
       "      <td>19.2</td>\n",
       "      <td>51</td>\n",
       "      <td>77</td>\n",
       "      <td>4.37</td>\n",
       "      <td>8</td>\n",
       "      <td>13.6</td>\n",
       "      <td>114.587985</td>\n",
       "      <td>12725974.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.8</td>\n",
       "      <td>0.492</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006</td>\n",
       "      <td>58.0</td>\n",
       "      <td>526</td>\n",
       "      <td>33</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.860004</td>\n",
       "      <td>81</td>\n",
       "      <td>459</td>\n",
       "      <td>18.8</td>\n",
       "      <td>52</td>\n",
       "      <td>83</td>\n",
       "      <td>6.11</td>\n",
       "      <td>81</td>\n",
       "      <td>15.9</td>\n",
       "      <td>13.154199</td>\n",
       "      <td>12383446.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.479</td>\n",
       "      <td>10.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2001</td>\n",
       "      <td>45.3</td>\n",
       "      <td>686</td>\n",
       "      <td>25</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>76</td>\n",
       "      <td>529</td>\n",
       "      <td>25.9</td>\n",
       "      <td>39</td>\n",
       "      <td>76</td>\n",
       "      <td>6.16</td>\n",
       "      <td>75</td>\n",
       "      <td>42.1</td>\n",
       "      <td>548.587312</td>\n",
       "      <td>12366165.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.427</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2002</td>\n",
       "      <td>44.8</td>\n",
       "      <td>73</td>\n",
       "      <td>25</td>\n",
       "      <td>4.43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>73</td>\n",
       "      <td>304</td>\n",
       "      <td>26.3</td>\n",
       "      <td>40</td>\n",
       "      <td>73</td>\n",
       "      <td>6.53</td>\n",
       "      <td>71</td>\n",
       "      <td>39.8</td>\n",
       "      <td>57.348340</td>\n",
       "      <td>125525.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.427</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2004</td>\n",
       "      <td>44.3</td>\n",
       "      <td>723</td>\n",
       "      <td>27</td>\n",
       "      <td>4.36</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68</td>\n",
       "      <td>31</td>\n",
       "      <td>27.1</td>\n",
       "      <td>42</td>\n",
       "      <td>67</td>\n",
       "      <td>7.13</td>\n",
       "      <td>65</td>\n",
       "      <td>33.6</td>\n",
       "      <td>454.366654</td>\n",
       "      <td>12777511.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>9.4</td>\n",
       "      <td>0.407</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>362 rows Ã— 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      0     1    2   3     4          5   6     7     8    9   10    11  12  \\\n",
       "14  2001  55.3  316  88  0.01  10.574728  63  8762  12.6  122  35  7.80  33   \n",
       "12  2003  56.7  295  87  0.01  11.089053  65   798  13.4  122  41  8.82  41   \n",
       "13  2002  56.2    3  88  0.01  16.887351  64  2486  13.0  122  36  7.76  36   \n",
       "3   2012  59.5  272  69  0.01  78.184215  67  2787  17.6   93  67  8.52  67   \n",
       "14  2001  73.6   14   1  4.25  96.205571  96    18  46.0    1  97  6.00  97   \n",
       "..   ...   ...  ...  ..   ...        ...  ..   ...   ...  ...  ..   ...  ..   \n",
       "7   2007  52.6  487  32  2.08  10.851482   8   535  19.2   51  77  4.37   8   \n",
       "8   2006  58.0  526  33  2.25   1.860004  81   459  18.8   52  83  6.11  81   \n",
       "13  2001  45.3  686  25  1.72   0.000000  76   529  25.9   39  76  6.16  75   \n",
       "12  2002  44.8   73  25  4.43   0.000000  73   304  26.3   40  73  6.53  71   \n",
       "10  2004  44.3  723  27  4.36   0.000000  68    31  27.1   42  67  7.13  65   \n",
       "\n",
       "      13           14          15    16    17     18    19  \n",
       "14   0.1   117.496980   2966463.0   2.1   2.4  0.340   5.9  \n",
       "12   0.1   198.728544   2364851.0  19.7  19.9  0.373   6.5  \n",
       "13   0.1   187.845950  21979923.0  19.9   2.2  0.341   6.2  \n",
       "3    0.1   669.959000   3696958.0  17.9  18.0  0.463   9.8  \n",
       "14   0.1  1326.973390     36173.0   2.1   2.1  0.662  10.6  \n",
       "..   ...          ...         ...   ...   ...    ...   ...  \n",
       "7   13.6   114.587985  12725974.0   6.9   6.8  0.492  11.1  \n",
       "8   15.9    13.154199  12383446.0   7.0   6.9  0.479  10.9  \n",
       "13  42.1   548.587312  12366165.0   1.6   1.7  0.427   9.8  \n",
       "12  39.8    57.348340    125525.0   1.2   1.3  0.427  10.0  \n",
       "10  33.6   454.366654  12777511.0   9.4   9.4  0.407   9.2  \n",
       "\n",
       "[362 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "important-grove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.9, 58.1, 57.3, ..., 44.5, 46. , 59.2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seperate training X and Y values\n",
    "train_X = training_data.iloc[:, 2:20].values\n",
    "train_Y = training_data.iloc[:, 1].values\n",
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b2aa58",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.68e+02, 6.60e+01, 1.00e-02, ..., 1.77e+01, 4.70e-01, 9.90e+00],\n",
       "       [2.87e+02, 8.00e+01, 3.00e-02, ..., 1.89e+01, 4.33e-01, 8.70e+00],\n",
       "       [2.95e+02, 8.40e+01, 3.00e-02, ..., 1.93e+01, 4.05e-01, 8.10e+00],\n",
       "       ...,\n",
       "       [7.15e+02, 2.60e+01, 4.06e+00, ..., 9.90e+00, 4.18e-01, 9.50e+00],\n",
       "       [6.65e+02, 2.40e+01, 1.68e+00, ..., 1.12e+01, 4.34e-01, 9.80e+00],\n",
       "       [3.71e+02, 2.30e+01, 6.50e+00, ..., 5.70e+00, 4.98e-01, 1.03e+01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cef65bf4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57.14274933 57.3879194  66.67050694 59.44438342 73.07135217 72.68389606\n",
      " 73.09182869 76.72991372 72.29834744 72.57466643 73.17726959 52.85453243\n",
      " 53.03938396 74.93365192 76.61016331 75.61665753 72.88459837 72.82893973\n",
      " 72.9906681  83.34414091 83.01653267 81.75483439 79.28632629 80.11086346\n",
      " 79.43845944 71.22869335 71.39513178 70.94247797 66.57287584 67.77114442\n",
      " 68.18146354 67.67066279 67.72809972 68.03780688 81.02078482 79.80266284\n",
      " 82.66249671 69.34797621 69.19704848 69.44419158 56.68053847 56.64579306\n",
      " 57.11097314 67.69426085 61.87525527 63.00785401 72.02346724 72.65077502\n",
      " 73.32915459 48.31674588 48.42150278 52.35996786 72.36070037 72.62314178\n",
      " 73.35267114 73.72121025 73.12568228 73.12809745 57.81322841 56.74456885\n",
      " 55.03928568 55.12424951 54.21170612 71.6859732  71.35078857 71.48634219\n",
      " 66.77086984 64.52091759 55.14006079 55.21824997 81.28061747 82.2570737\n",
      " 82.97936834 51.09629558 51.55853158 52.09505582 54.64808202 79.22591881\n",
      " 78.28943244 72.32359763 72.33128387 72.55774875 72.41793409 72.6208792\n",
      " 73.29843135 61.68195548 61.2598335  62.1569468  74.68539606 75.32668698\n",
      " 76.58053176 76.95349231 77.18960997 77.8218738  78.23066195 79.27478416\n",
      " 61.75307105 61.59702146 70.06615713 70.31542172 68.69051088 73.48685885\n",
      " 73.13467074 73.5476103  68.82188841 70.57047117 70.14437789 58.07149356\n",
      " 57.41927189 74.00926629 74.60472139 74.95120111 58.40502105 58.25772614\n",
      " 68.26854846 69.00417285 68.38429778 80.58419204 81.09323751 81.53246546\n",
      " 61.42961646 61.22088481 72.89197884 72.78271731 73.31073631 80.93244486\n",
      " 81.15073177 80.58848273 57.17438257 58.94966288 58.95436909 78.29470518\n",
      " 78.98253926 80.09790091 72.73263705 70.49868045 57.06253043 55.35857283\n",
      " 56.89294276 57.5057629  65.61294652 65.7597933  65.85323764 62.72454942\n",
      " 69.78388969 69.84669337 71.72788685 65.11010697 66.47177423 66.64102714\n",
      " 67.0047458  67.16485278 67.28675095 68.89851884 66.25253677 66.7325457\n",
      " 82.59068893 81.25918387 81.4443672  81.99635708 80.48074843 80.66785393\n",
      " 83.46429967 72.50037226 73.1181261  73.25305905 73.55034082 73.72660392\n",
      " 73.76755933 64.7844515  64.9989644  64.86970191 51.26678937 52.26470438\n",
      " 53.28183379 65.95443232 66.23417451 67.98113147 69.32433137 69.71096053\n",
      " 74.36006106 72.4201329  71.74075384 72.63928817 46.14541672 47.09312008\n",
      " 47.09782193 59.67558119 59.31216275 72.64750274 72.54869202 72.26502325\n",
      " 78.79779642 78.95907884 79.6836301  59.6407899  60.35611353 61.60303621\n",
      " 47.19338971 47.93939799 49.00247197 73.44699251 73.57033024 74.02981423\n",
      " 72.73501923 72.63011149 73.56501028 55.59681811 56.35611005 56.23709613\n",
      " 78.03421912 78.57533835 79.15229765 62.70288291 63.31684724 71.4771604\n",
      " 71.0392218  72.38920987 74.0973239  74.60399633 75.38692348 64.56629945\n",
      " 65.09153492 64.77775664 75.55777645 74.93435703 68.5524475  68.76418502\n",
      " 71.34705432 51.63004366 51.74134039 51.30282085 64.6998873  64.30789129\n",
      " 64.75305399 63.3092248  65.61946222 66.32754341 67.45251882 81.97855826\n",
      " 70.5664335  71.3048147  72.07935356 58.5583829  60.79407505 54.79388304\n",
      " 52.3461462  65.28489717 66.27389854 65.42664451 74.66134469 74.84236826\n",
      " 75.4952273  59.78087403 60.01038118 61.22129227 72.68771343 72.84184267\n",
      " 73.09284632 73.52174585 73.76275452 73.7856634  67.60101882 67.62925422\n",
      " 67.65479113 74.13705851 74.31263347 74.4690877  77.69626365 77.7415613\n",
      " 78.09567005 71.85254885 71.65902106 72.39823909 66.30287514 66.295413\n",
      " 66.61471218 55.46916226 55.70889713 55.77807343 73.57663957 73.88376127\n",
      " 73.82412226 63.04954507 62.63614331 64.67233076 60.4571385  61.90976193\n",
      " 62.0888815  74.20269184 74.13549928 74.09013491 70.81770931 71.45946483\n",
      " 71.26169641 52.04469406 51.58542955 66.05952928 67.28010239 68.13528242\n",
      " 56.33056892 55.43513785 54.29125537 80.13818925 81.1278241  82.07066527\n",
      " 69.84811468 73.92483405 73.89862524 70.58739328 69.80599359 47.78767373\n",
      " 47.55702198 47.39123084 81.98346911 72.57384279 72.57488267 66.6294761\n",
      " 67.4034164  66.94901821 69.55929272 70.04676056 70.59194702 67.88516158\n",
      " 67.32305802 60.07401385 58.2619271  72.75147291 72.82650279 73.00517498\n",
      " 70.1789396  71.31259404 70.82916022 73.42071792 72.39959535 73.48343179\n",
      " 72.94686978 73.3685069  73.11940006 65.01384672 65.12390927 63.53466854\n",
      " 54.03233697 53.47771863 53.97478883 67.4616653  67.59305226 67.96828364\n",
      " 75.98104162 75.87204466 76.32220509 67.76622898 67.88105038 67.897848\n",
      " 67.86404864 68.33254961 69.16854036 51.8704494  50.8751138  47.35064646\n",
      " 48.66107557 45.62795024]\n"
     ]
    }
   ],
   "source": [
    "#Train Model\n",
    "regressor = RandomForestRegressor(n_estimators = 300, max_leaf_nodes = 150, bootstrap = True)\n",
    "# Fit the regressor with x and y data\n",
    "regressor.fit(train_X, train_Y)\n",
    "# Load testing values\n",
    "test_X = testing_data.iloc[:, 2:20].values\n",
    "test_Y = testing_data.iloc[:, 1].values\n",
    "# Predict with testing X\n",
    "predict_Y = regressor.predict(test_X)\n",
    "print(predict_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0755ecfe",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.16e+02, 8.80e+01, 1.00e-02, ..., 2.40e+00, 3.40e-01, 5.90e+00],\n",
       "       [2.95e+02, 8.70e+01, 1.00e-02, ..., 1.99e+01, 3.73e-01, 6.50e+00],\n",
       "       [3.00e+00, 8.80e+01, 1.00e-02, ..., 2.20e+00, 3.41e-01, 6.20e+00],\n",
       "       ...,\n",
       "       [6.86e+02, 2.50e+01, 1.72e+00, ..., 1.70e+00, 4.27e-01, 9.80e+00],\n",
       "       [7.30e+01, 2.50e+01, 4.43e+00, ..., 1.30e+00, 4.27e-01, 1.00e+01],\n",
       "       [7.23e+02, 2.70e+01, 4.36e+00, ..., 9.40e+00, 4.07e-01, 9.20e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9238945",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([55.3, 56.7, 56.2, 59.5, 73.6, 72.8, 73.3, 76.9, 72.9, 73.4, 73.8,\n",
       "       49.6, 49.1, 74.1, 74.7, 74.9, 72.6, 72.6, 73. , 79.9, 86. , 81. ,\n",
       "       78.6, 78.7, 79.3, 67.8, 68.4, 68.4, 67.3, 67.8, 68.2, 67.7, 67.2,\n",
       "       68.2, 78. , 78. , 78.8, 68.2, 68.5, 68.7, 55.8, 56.1, 56.5, 61.7,\n",
       "       62.5, 64.2, 75. , 75.7, 75.4, 46.7, 46. , 48.1, 71. , 71.4, 72. ,\n",
       "       71.6, 71.8, 72.2, 57.5, 56.1, 53.4, 54.1, 54.8, 71.1, 71.4, 71.8,\n",
       "       66.6, 65.6, 53.6, 53.3, 80. , 81. , 85. , 49.2, 53. , 51.8, 57. ,\n",
       "       79.1, 79.6, 72.2, 72.7, 73.5, 71.5, 71.8, 72.8, 59.8, 60. , 63. ,\n",
       "       77.5, 78.3, 77.7, 76.6, 76.3, 78.2, 78.4, 78.6, 61.3, 69. , 71.2,\n",
       "       71.4, 69.3, 73.4, 73.6, 74.4, 68.9, 73. , 70. , 59.1, 58.8, 72.8,\n",
       "       73. , 73. , 61.8, 68. , 67.8, 67.9, 68.1, 79. , 79.2, 82. , 61.6,\n",
       "       61.4, 73. , 71.7, 72.3, 78.3, 78.4, 79.1, 57.9, 58.3, 58.9, 78.7,\n",
       "       79. , 79.2, 75. , 69.7, 57.8, 57.3, 56.7, 57.6, 65.3, 65.1, 65. ,\n",
       "       62.7, 71.3, 71.6, 72.2, 64.4, 64.8, 65.2, 66.5, 66.7, 65.3, 66.8,\n",
       "       64.7, 65.9, 84. , 79.3, 79.3, 81. , 79.8, 80. , 89. , 73.3, 73.5,\n",
       "       74. , 71.9, 72.1, 72.5, 64.4, 64.7, 64.7, 52.4, 53. , 54.1, 64.3,\n",
       "       64.6, 64.8, 69.9, 73. , 71. , 73. , 73.2, 73.7, 44.8, 44.5, 45.3,\n",
       "       67. , 59.2, 71.2, 71.4, 71.6, 78. , 78.3, 78.7, 59.9, 64. , 69. ,\n",
       "       44.6, 45.1, 46. , 72.7, 72.9, 73.2, 78. , 71.8, 73.4, 52.8, 53.6,\n",
       "       54.3, 78.7, 79. , 79.3, 61.2, 69. , 71.5, 71.5, 71.9, 75. , 75. ,\n",
       "       75.4, 63.2, 63.8, 64. , 75.3, 74.6, 69. , 69.5, 72. , 49.8, 54. ,\n",
       "       58. , 63.5, 63.9, 64.2, 64.3, 64.7, 65.4, 66. , 81.1, 73. , 75. ,\n",
       "       71. , 58.2, 63. , 55. , 49.8, 63.7, 62.9, 64.2, 75.7, 75.8, 75.8,\n",
       "       59.1, 59.3, 59.9, 71.9, 72.1, 72.3, 72.2, 72.8, 74.2, 66.8, 66.8,\n",
       "       67.3, 74.2, 74.5, 74.9, 76.9, 77.2, 78. , 78. , 77. , 71.7, 64.8,\n",
       "       64.9, 65. , 52. , 53.4, 55.3, 75. , 76. , 71.4, 63.8, 64.3, 64.7,\n",
       "       65. , 61.3, 62.1, 73. , 73.6, 73.8, 72. , 72.1, 72.1, 48.1, 47.1,\n",
       "       66.2, 66.5, 67.1, 56. , 54.9, 53.7, 79.4, 79.5, 81. , 69.1, 74.2,\n",
       "       73.8, 69.5, 69.3, 47.1, 46.4, 45.6, 81.7, 73. , 72.8, 65.2, 65.9,\n",
       "       65.5, 71.2, 71.4, 71.6, 67.4, 66.6, 58.9, 56.7, 71.8, 71.9, 72.2,\n",
       "       69.3, 69.4, 69.5, 73.2, 73.5, 74. , 78. , 71.2, 72. , 63.4, 63.5,\n",
       "       63.3, 51. , 51.3, 53.2, 67.7, 67.6, 67.4, 75.2, 75.4, 75.4, 67.2,\n",
       "       67.8, 67.3, 69.1, 69.3, 69.6, 52.6, 58. , 45.3, 44.8, 44.3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c05682b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  32.38\n"
     ]
    }
   ],
   "source": [
    "#basline estimate\n",
    "# The baseline predictions are the historical averages\n",
    "baseline_preds = testing_data.iloc[:, 8:9].values\n",
    "# Baseline errors, and display average baseline error\n",
    "baseline_errors = abs(baseline_preds - test_Y)\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8954ac93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.37 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = regressor.predict(test_X)\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_Y)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba1c2a22",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.88 %.\n"
     ]
    }
   ],
   "source": [
    "#Determine Performance Metrics\n",
    "# Calculate mean absolute percentage error\n",
    "feature = 100 * (errors / predict_Y)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(feature)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eced860a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable:                   16 Importance: 0.54\n",
      "Variable:                   11 Importance: 0.27\n",
      "Variable:                    0 Importance: 0.11\n",
      "Variable:                    2 Importance: 0.01\n",
      "Variable:                    6 Importance: 0.01\n",
      "Variable:                    9 Importance: 0.01\n",
      "Variable:                   14 Importance: 0.01\n",
      "Variable:                   15 Importance: 0.01\n",
      "Variable:                   17 Importance: 0.01\n",
      "Variable:                    1 Importance: 0.0\n",
      "Variable:                    3 Importance: 0.0\n",
      "Variable:                    4 Importance: 0.0\n",
      "Variable:                    5 Importance: 0.0\n",
      "Variable:                    7 Importance: 0.0\n",
      "Variable:                    8 Importance: 0.0\n",
      "Variable:                   10 Importance: 0.0\n",
      "Variable:                   12 Importance: 0.0\n",
      "Variable:                   13 Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(regressor.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(testing_data, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0356118d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_important = training_data.iloc[:, 11:17].values\n",
    "test_important = testing_data.iloc[:, 11:17].values\n",
    "updated_testing = testing_data.iloc[:, 11:17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3cd56408",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable:                   11 Importance: 0.11\n",
      "Variable:                   13 Importance: 0.01\n",
      "Variable:                   12 Importance: 0.0\n",
      "Variable:                   14 Importance: 0.0\n",
      "Variable:                   15 Importance: 0.0\n",
      "Variable:                   16 Importance: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Get numerical feature importances\n",
    "importances = list(regressor.feature_importances_)\n",
    "# List of tuples with variable and importance\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(updated_testing, importances)]\n",
    "# Sort the feature importances by most important first\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "# Print out the feature and importances\n",
    "[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9e27e732",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2.24 degrees.\n",
      "Accuracy: 96.55 %.\n"
     ]
    }
   ],
   "source": [
    "# New random forest with only the two most important variables\n",
    "rf_most_important = RandomForestRegressor(n_estimators = 300, max_leaf_nodes = 150, bootstrap = True)\n",
    "# Train the random forest\n",
    "rf_most_important.fit(train_important, train_Y)\n",
    "# Make predictions and determine the error\n",
    "predictions = rf_most_important.predict(test_important)\n",
    "errors = abs(predictions - test_Y)\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "mape = np.mean(100 * (errors / test_Y))\n",
    "accuracy = 100 - mape\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a985c98a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# x_value = list(range(len(importances)))\n",
    "# print(x_value)\n",
    "#\n",
    "# plt.bar(x_value, importances, orientation = 'vertical')\n",
    "#\n",
    "# plt.xticks(x_value, testing_data, rotation = 6)\n",
    "#\n",
    "# plt.ylabel('importance');\n",
    "# plt.xlable('Variable');\n",
    "# plt.title('Variable Importance');\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "meaningful-reading",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss percentage on testing set: 0.18678403687826156\n",
      "MSE loss on testing set: 3.985287435982033\n",
      "Random forest regressor score: 0.9525237542440262\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "# calculate the percentage\n",
    "for i in range(len(test_Y)):\n",
    "    dif = (abs(float(test_Y[i] - predict_Y[i])) / float(test_Y[i])) * 100\n",
    "    losses.append(dif)\n",
    "#calculate total value of loss\n",
    "totalValue = np.sum(losses) % 100\n",
    "print(\"Loss percentage on testing set: \" + str(totalValue / len(losses)))\n",
    "errors = mean_squared_error(test_Y, predict_Y)\n",
    "print(\"MSE loss on testing set: \" + str(mean_squared_error(test_Y, predict_Y)))\n",
    "print(\"Random forest regressor score: \" + str(regressor.score(test_X, test_Y)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}